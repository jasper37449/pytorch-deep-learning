{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "A way to represent datas (array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "vector = torch.tensor([7, 7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 2],\n",
       "        [3, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "matrix = torch.tensor([[1, 1], [2, 2], [3, 3]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[9, 8, 7],\n",
       "         [6, 5, 4],\n",
       "         [3, 2, 1]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor\n",
    "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[9, 8, 7], [6, 5, 4], [3, 2, 1]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4302, 0.4051, 0.1899, 0.8468, 0.2952],\n",
       "         [0.8830, 0.8391, 0.7698, 0.4949, 0.1042],\n",
       "         [0.7413, 0.2917, 0.7902, 0.3828, 0.9766],\n",
       "         [0.1291, 0.4885, 0.1867, 0.1856, 0.3209],\n",
       "         [0.0937, 0.0258, 0.0519, 0.0348, 0.5498]],\n",
       "\n",
       "        [[0.5074, 0.2173, 0.5263, 0.4303, 0.2191],\n",
       "         [0.4833, 0.6036, 0.3117, 0.9520, 0.6582],\n",
       "         [0.2857, 0.0672, 0.4378, 0.1238, 0.1853],\n",
       "         [0.2132, 0.3286, 0.2704, 0.7941, 0.7723],\n",
       "         [0.8401, 0.8024, 0.1934, 0.9230, 0.5536]],\n",
       "\n",
       "        [[0.3446, 0.0493, 0.6406, 0.9298, 0.4205],\n",
       "         [0.6101, 0.5262, 0.0045, 0.0416, 0.4434],\n",
       "         [0.1600, 0.7011, 0.8314, 0.6026, 0.4513],\n",
       "         [0.0582, 0.9847, 0.5409, 0.0789, 0.1373],\n",
       "         [0.9917, 0.1710, 0.5336, 0.5027, 0.8885]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random tensor\n",
    "random = torch.rand(3, 5, 5)\n",
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image = torch.rand(3, 224, 224) #color channel (RGB), height, width\n",
    "random_image.shape, random_image.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique tensors, zero and One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 4)\n",
    "ones = torch.ones(1, 2)\n",
    "zeros, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype #default type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range of Tensors and Tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranged_num = torch.arange(0, 1000, 77) # [Start, End), +1 parameter -> step (spaces of each num)\n",
    "ranged_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_zero = torch.zeros_like(ranged_num)\n",
    "range_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types of Tensors\n",
    "\n",
    "3 Big notes for this part :\n",
    "1. Use correct tensor data type (tensor.dtype)\n",
    "2. Use correct tensor size/shape (tensor.shape)\n",
    "3. Use correct tensor device (tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]), torch.float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype = None, #Data type of tensor, default is float32\n",
    "                               device = None, #Normally \"cpu\" or \"cuda\"(gpu)\n",
    "                               requires_grad = False) # Track gradients\n",
    "float_32_tensor, float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16), torch.float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor, float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "Including :\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11, 12, 13]), tensor([10, 20, 30]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a tensor and do some math operations\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10, tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals : tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals : {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6821, 0.7965, 0.9769, 0.6432, 1.0576],\n",
       "         [0.9706, 0.5444, 0.9029, 0.6027, 0.7971]]),\n",
       " torch.Size([3]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix multiplication\n",
    "##torch.mm(a, b) torch.matmul(a, b)\n",
    "torch.matmul(torch.rand(2, 3), torch.rand(3, 5)), tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplying torch.Size([2, 3]) with torch.Size([2, 3]) will cause error, \n",
      " thus we can use transpose to change the matrix's shape\n",
      "Pre-transpose : torch.Size([2, 3])\n",
      "Post-transpose : torch.Size([3, 2])\n",
      "Thus multiplication of 2 matrix would be \n",
      "tensor([[0.2415, 0.1746],\n",
      "        [0.4809, 0.3504]])\n"
     ]
    }
   ],
   "source": [
    "#Matrix Transpose\n",
    "tensorA = torch.rand(2, 3)\n",
    "tensorB = torch.rand(2, 3)\n",
    "print(f\"Multiplying {tensorA.shape} with {tensorB.shape} will cause error, \\n thus we can use transpose to change the matrix's shape\")\n",
    "print(f\"Pre-transpose : {tensorB.shape}\\nPost-transpose : {tensorB.T.shape}\")\n",
    "print(f\"Thus multiplication of 2 matrix would be \\n{torch.matmul(tensorA, tensorB.T)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor's min, max, sum, mean, etc (aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor\n",
    "tensor = torch.arange(0, 100, 10,)\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(90), tensor(90))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Min and Max\n",
    "torch.min(tensor), tensor.min(), torch.max(tensor), tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean and Sum\n",
    "#For mean, error with int64 type, so we change it to float32\n",
    "torch.mean(tensor.type(torch.float32)), torch.sum(tensor)\n",
    "#tensor.type(torch.float32).mean()      tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positional min and max\n",
    "x = tensor\n",
    "x.argmin() #Find min and return the index\n",
    "x.argmax() #Find max and return the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensor on top of each other (vstack / vertical stack) or side by side (hstack / horizontal stack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape a tensor\n",
    "x_reshaped = x.reshape(3, 3)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(9, 1)\n",
    "z, z.shape\n",
    "# Note that in this case, z and x shares the same memory, so if x is changed, it will affect z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors\n",
    "x_stack = torch.stack([x, x, x, x], dim = 1)\n",
    "x_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(1, 9)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before squeeze : tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape : torch.Size([1, 9])\n",
      "After squeeze : tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Shape after squeeze : torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "#Squeeze removes all 1 dimensions from a tensor, one may say it removes the useless dimensions of a tensor\n",
    "print(f\"Before squeeze : {y}\")\n",
    "print(f\"Shape : {y.shape}\")\n",
    "y_squeezed = y.squeeze()\n",
    "print(f\"After squeeze : {y_squeezed}\")\n",
    "print(f\"Shape after squeeze : {y_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before unsqueeze : tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Shape : torch.Size([9])\n",
      "After squeeze : tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape after squeeze : torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "#Unsqueeze adds a dimension to a target, in a specific location\n",
    "print(f\"Before unsqueeze : {y_squeezed}\")\n",
    "print(f\"Shape : {y_squeezed.shape}\")\n",
    "y_unsqueezed = y_squeezed.unsqueeze(dim = 0)\n",
    "print(f\"After squeeze : {y_unsqueezed}\")\n",
    "print(f\"Shape after squeeze : {y_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3]), torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Permute [torch.permute(tensor, (new_dim))] returns a view of a tensor, with its dimensions rearranged\n",
    "z = torch.tensor([[[1, 1, 1]], [[1, 1, 1]]])\n",
    "z.shape, torch.permute(z, (1, 0, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1]]]),\n",
       " tensor([[[1, 1, 1],\n",
       "          [1, 1, 1]]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, torch.permute(z, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and NumPy\n",
    "Sometimes, we need numpy values in pytorch and vice versa, so we can switch a np array -> tensor or tensor -> np array\n",
    "* torch.from_numpy(np_array_name) (np_array -> tensor, the default datatype of this action is numpy's datatype)\n",
    "* tensor_name.numpy() (tensor -> np_array, the default datatype is the tensor's datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy to PyTorch\n",
    "arr = np.arange(1, 10)\n",
    "tensor_arr = torch.from_numpy(arr)\n",
    "arr, tensor_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch to NumPy\n",
    "tensorx = torch.arange(1, 10)\n",
    "arr_np = tensorx.numpy()\n",
    "tensorx, arr_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take the random out of random)\n",
    "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
    "\n",
    "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
    "\n",
    "How does this relate to neural networks and deep learning then?\n",
    "\n",
    "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
    "\n",
    "In short:\n",
    "\n",
    "`start with random numbers -> tensor operations -> try to make better (again and again and again)`\n",
    "\n",
    "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
    "\n",
    "Why?\n",
    "\n",
    "So you can perform repeatable experiments.\n",
    "\n",
    "For example, you create an algorithm capable of achieving X performance.\n",
    "\n",
    "And then your friend tries it out to verify you're not crazy.\n",
    "\n",
    "How could they do such a thing?\n",
    "\n",
    "That's where reproducibility comes in.\n",
    "\n",
    "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
    "\n",
    "Let's see a brief example of reproducibility in PyTorch.\n",
    "\n",
    "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.9179, 0.8829, 0.3671, 0.2523],\n",
      "        [0.4117, 0.3291, 0.8586, 0.7649],\n",
      "        [0.8909, 0.6356, 0.1138, 0.9691]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.7175, 0.9745, 0.7322, 0.0500],\n",
      "        [0.4113, 0.1008, 0.8430, 0.3450],\n",
      "        [0.5774, 0.5568, 0.2783, 0.5962]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch setup with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "#Default tensor (on CPU)\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(x, x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move tensor to GPU (if available)\n",
    "x_new = x.to(device)\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy does not work with GPU, so we need to move gpu tensors back to cpu\n",
    "x_cpu = x_new.cpu().numpy()\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
